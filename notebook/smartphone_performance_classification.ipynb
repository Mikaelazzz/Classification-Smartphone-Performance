{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ“± Klasifikasi Kinerja Smartphone\n",
        "\n",
        "Notebook ini membangun model klasifikasi untuk menentukan:\n",
        "1. **Kelas Harga**: Entry Level, Mid Range, High End, Flagship\n",
        "2. **Jenis Penggunaan**: Gaming, Daily Use, Photography, Business, All-Rounder\n",
        "\n",
        "**Dataset**: smartphones.csv (981 data smartphone)\n",
        "\n",
        "**Algoritma**: Random Forest dengan anti-overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Plot settings\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "print(\"âœ… Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv('../dataset/smartphones.csv')\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset info\n",
        "print(\"Dataset Info:\")\n",
        "print(\"=\" * 50)\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check missing values\n",
        "missing = df.isnull().sum()\n",
        "missing_pct = (missing / len(df) * 100).round(2)\n",
        "missing_df = pd.DataFrame({'Missing': missing, 'Percentage': missing_pct})\n",
        "print(\"Missing Values:\")\n",
        "print(missing_df[missing_df['Missing'] > 0].sort_values('Missing', ascending=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Statistical summary\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Price distribution\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Histogram\n",
        "axes[0].hist(df['price'], bins=50, color='steelblue', edgecolor='white')\n",
        "axes[0].set_xlabel('Price (â‚¹)')\n",
        "axes[0].set_ylabel('Count')\n",
        "axes[0].set_title('Distribution of Smartphone Prices')\n",
        "\n",
        "# Box plot\n",
        "axes[1].boxplot(df['price'].dropna())\n",
        "axes[1].set_ylabel('Price (â‚¹)')\n",
        "axes[1].set_title('Price Box Plot')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Brand distribution\n",
        "brand_counts = df['brand_name'].value_counts().head(15)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "brand_counts.plot(kind='bar', color='steelblue', edgecolor='white')\n",
        "plt.xlabel('Brand')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Top 15 Smartphone Brands')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Processor brand distribution\n",
        "processor_counts = df['processor_brand'].value_counts()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "processor_counts.plot(kind='pie', autopct='%1.1f%%', colors=plt.cm.Set3.colors)\n",
        "plt.title('Processor Brand Distribution')\n",
        "plt.ylabel('')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Key features scatter plots\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# RAM vs Price\n",
        "axes[0, 0].scatter(df['ram_capacity'], df['price'], alpha=0.5, c='steelblue')\n",
        "axes[0, 0].set_xlabel('RAM (GB)')\n",
        "axes[0, 0].set_ylabel('Price (â‚¹)')\n",
        "axes[0, 0].set_title('RAM vs Price')\n",
        "\n",
        "# Processor Speed vs Price\n",
        "axes[0, 1].scatter(df['processor_speed'], df['price'], alpha=0.5, c='green')\n",
        "axes[0, 1].set_xlabel('Processor Speed (GHz)')\n",
        "axes[0, 1].set_ylabel('Price (â‚¹)')\n",
        "axes[0, 1].set_title('Processor Speed vs Price')\n",
        "\n",
        "# Primary Camera vs Price\n",
        "axes[1, 0].scatter(df['primary_camera_rear'], df['price'], alpha=0.5, c='orange')\n",
        "axes[1, 0].set_xlabel('Primary Camera (MP)')\n",
        "axes[1, 0].set_ylabel('Price (â‚¹)')\n",
        "axes[1, 0].set_title('Primary Camera vs Price')\n",
        "\n",
        "# Refresh Rate vs Price\n",
        "axes[1, 1].scatter(df['refresh_rate'], df['price'], alpha=0.5, c='purple')\n",
        "axes[1, 1].set_xlabel('Refresh Rate (Hz)')\n",
        "axes[1, 1].set_ylabel('Price (â‚¹)')\n",
        "axes[1, 1].set_title('Refresh Rate vs Price')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5G distribution\n",
        "has_5g_counts = df['has_5g'].value_counts()\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Pie chart 5G\n",
        "axes[0].pie(has_5g_counts, labels=['5G', 'Non-5G'], autopct='%1.1f%%', \n",
        "           colors=['#2ecc71', '#e74c3c'], startangle=90)\n",
        "axes[0].set_title('5G Support Distribution')\n",
        "\n",
        "# Price comparison 5G vs Non-5G\n",
        "df.boxplot(column='price', by='has_5g', ax=axes[1])\n",
        "axes[1].set_xlabel('Has 5G')\n",
        "axes[1].set_ylabel('Price (â‚¹)')\n",
        "axes[1].set_title('Price Comparison: 5G vs Non-5G')\n",
        "plt.suptitle('')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a copy for preprocessing\n",
        "df_clean = df.copy()\n",
        "\n",
        "# Drop rows with missing price (target variable)\n",
        "df_clean = df_clean.dropna(subset=['price'])\n",
        "print(f\"After dropping missing prices: {len(df_clean)} rows\")\n",
        "\n",
        "# Fill missing values\n",
        "# Numeric columns - fill with median\n",
        "numeric_cols = ['rating', 'processor_speed', 'fast_charging', 'num_front_cameras']\n",
        "for col in numeric_cols:\n",
        "    if col in df_clean.columns:\n",
        "        df_clean[col] = df_clean[col].fillna(df_clean[col].median())\n",
        "\n",
        "# Categorical columns - fill with mode\n",
        "categorical_cols = ['processor_brand', 'os']\n",
        "for col in categorical_cols:\n",
        "    if col in df_clean.columns:\n",
        "        df_clean[col] = df_clean[col].fillna(df_clean[col].mode()[0])\n",
        "\n",
        "# Extended memory - fill with 0 if not available\n",
        "df_clean['extended_upto'] = df_clean['extended_upto'].fillna(0)\n",
        "\n",
        "print(f\"\\nMissing values after cleaning:\")\n",
        "print(df_clean.isnull().sum().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create Price Class (Target Variable 1)\n",
        "def classify_price(price):\n",
        "    if price < 10000:\n",
        "        return 0  # Entry Level\n",
        "    elif price < 25000:\n",
        "        return 1  # Mid Range\n",
        "    elif price < 50000:\n",
        "        return 2  # High End\n",
        "    else:\n",
        "        return 3  # Flagship\n",
        "\n",
        "df_clean['price_class'] = df_clean['price'].apply(classify_price)\n",
        "\n",
        "# Price class mapping\n",
        "price_class_names = {\n",
        "    0: 'Entry Level',\n",
        "    1: 'Mid Range',\n",
        "    2: 'High End',\n",
        "    3: 'Flagship'\n",
        "}\n",
        "\n",
        "print(\"Price Class Distribution:\")\n",
        "print(df_clean['price_class'].value_counts().sort_index().rename(price_class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create Usage Type (Target Variable 2)\n",
        "def classify_usage(row):\n",
        "    # Gaming: High refresh rate, fast processor, lots of RAM\n",
        "    is_gaming = (\n",
        "        row['refresh_rate'] >= 120 and \n",
        "        row['processor_speed'] >= 2.8 and \n",
        "        row['ram_capacity'] >= 8\n",
        "    )\n",
        "    \n",
        "    # Photography: High camera specs\n",
        "    is_photography = (\n",
        "        row['primary_camera_rear'] >= 64 and \n",
        "        row['primary_camera_front'] >= 32\n",
        "    )\n",
        "    \n",
        "    # Business: NFC, good specs\n",
        "    is_business = (\n",
        "        row['has_nfc'] == True and \n",
        "        row['ram_capacity'] >= 6 and \n",
        "        row['internal_memory'] >= 128\n",
        "    )\n",
        "    \n",
        "    # Classification logic\n",
        "    if is_gaming:\n",
        "        return 'Gaming'\n",
        "    elif is_photography:\n",
        "        return 'Photography'\n",
        "    elif is_business:\n",
        "        return 'Business'\n",
        "    elif row['price'] < 15000 and row['battery_capacity'] >= 5000:\n",
        "        return 'Daily Use'\n",
        "    else:\n",
        "        return 'All-Rounder'\n",
        "\n",
        "df_clean['usage_type'] = df_clean.apply(classify_usage, axis=1)\n",
        "\n",
        "print(\"\\nUsage Type Distribution:\")\n",
        "print(df_clean['usage_type'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize target distributions\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Price Class distribution\n",
        "price_counts = df_clean['price_class'].value_counts().sort_index()\n",
        "colors = ['#e74c3c', '#f39c12', '#3498db', '#2ecc71']\n",
        "axes[0].bar([price_class_names[i] for i in price_counts.index], price_counts.values, color=colors)\n",
        "axes[0].set_xlabel('Price Class')\n",
        "axes[0].set_ylabel('Count')\n",
        "axes[0].set_title('Price Class Distribution')\n",
        "axes[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Usage Type distribution\n",
        "usage_counts = df_clean['usage_type'].value_counts()\n",
        "usage_colors = ['#9b59b6', '#1abc9c', '#e67e22', '#34495e', '#2980b9']\n",
        "axes[1].bar(usage_counts.index, usage_counts.values, color=usage_colors[:len(usage_counts)])\n",
        "axes[1].set_xlabel('Usage Type')\n",
        "axes[1].set_ylabel('Count')\n",
        "axes[1].set_title('Usage Type Distribution')\n",
        "axes[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select features for model\n",
        "feature_columns = [\n",
        "    'num_cores',\n",
        "    'processor_speed',\n",
        "    'ram_capacity',\n",
        "    'internal_memory',\n",
        "    'battery_capacity',\n",
        "    'screen_size',\n",
        "    'refresh_rate',\n",
        "    'primary_camera_rear',\n",
        "    'primary_camera_front',\n",
        "    'resolution_width',\n",
        "    'resolution_height',\n",
        "    'has_5g',\n",
        "    'has_nfc',\n",
        "    'fast_charging_available',\n",
        "    'num_rear_cameras'\n",
        "]\n",
        "\n",
        "# Convert boolean to int\n",
        "df_clean['has_5g'] = df_clean['has_5g'].astype(int)\n",
        "df_clean['has_nfc'] = df_clean['has_nfc'].astype(int)\n",
        "df_clean['fast_charging_available'] = df_clean['fast_charging_available'].astype(int)\n",
        "\n",
        "# Prepare features\n",
        "X = df_clean[feature_columns].copy()\n",
        "\n",
        "# Handle any remaining missing values\n",
        "X = X.fillna(X.median())\n",
        "\n",
        "print(f\"Features shape: {X.shape}\")\n",
        "print(f\"\\nFeature columns: {feature_columns}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation matrix\n",
        "plt.figure(figsize=(14, 10))\n",
        "corr_matrix = X.corr()\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
        "plt.title('Feature Correlation Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare target variables\n",
        "y_price = df_clean['price_class']\n",
        "\n",
        "# Encode usage type\n",
        "usage_encoder = LabelEncoder()\n",
        "y_usage = usage_encoder.fit_transform(df_clean['usage_type'])\n",
        "\n",
        "print(f\"Price classes: {np.unique(y_price)}\")\n",
        "print(f\"Usage classes: {usage_encoder.classes_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Training - Price Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data for Price Class model\n",
        "X_train_price, X_test_price, y_train_price, y_test_price = train_test_split(\n",
        "    X, y_price, test_size=0.2, random_state=42, stratify=y_price\n",
        ")\n",
        "\n",
        "print(f\"Training set: {X_train_price.shape[0]} samples\")\n",
        "print(f\"Test set: {X_test_price.shape[0]} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_price)\n",
        "X_test_scaled = scaler.transform(X_test_price)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hyperparameter tuning with GridSearchCV (Anti-Overfitting)\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 150, 200],\n",
        "    'max_depth': [8, 10, 12],  # Limited depth to prevent overfitting\n",
        "    'min_samples_split': [5, 10],  # Minimum samples to split\n",
        "    'min_samples_leaf': [2, 4],  # Minimum samples in leaf\n",
        "    'max_features': ['sqrt', 'log2']  # Limited features per split\n",
        "}\n",
        "\n",
        "print(\"Starting GridSearchCV for Price Class model...\")\n",
        "print(\"This may take a few minutes...\\n\")\n",
        "\n",
        "rf_price = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "\n",
        "grid_search_price = GridSearchCV(\n",
        "    rf_price, \n",
        "    param_grid, \n",
        "    cv=5,  # 5-fold cross-validation\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_search_price.fit(X_train_scaled, y_train_price)\n",
        "\n",
        "print(f\"\\nBest Parameters: {grid_search_price.best_params_}\")\n",
        "print(f\"Best CV Score: {grid_search_price.best_score_:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use best model\n",
        "best_rf_price = grid_search_price.best_estimator_\n",
        "\n",
        "# Predictions\n",
        "y_train_pred = best_rf_price.predict(X_train_scaled)\n",
        "y_test_pred = best_rf_price.predict(X_test_scaled)\n",
        "\n",
        "# Check for overfitting\n",
        "train_accuracy = accuracy_score(y_train_price, y_train_pred)\n",
        "test_accuracy = accuracy_score(y_test_price, y_test_pred)\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"PRICE CLASS MODEL EVALUATION\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Difference: {train_accuracy - test_accuracy:.4f}\")\n",
        "\n",
        "if (train_accuracy - test_accuracy) < 0.05:\n",
        "    print(\"\\nâœ… Model is NOT overfitting (difference < 5%)\")\n",
        "else:\n",
        "    print(\"\\nâš ï¸ Model might be overfitting\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cross-validation scores\n",
        "cv_scores = cross_val_score(best_rf_price, X_train_scaled, y_train_price, cv=5)\n",
        "print(f\"\\nCross-Validation Scores: {cv_scores}\")\n",
        "print(f\"Mean CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Classification Report\n",
        "print(\"\\nClassification Report (Price Class):\")\n",
        "print(\"=\"*50)\n",
        "target_names = ['Entry Level', 'Mid Range', 'High End', 'Flagship']\n",
        "print(classification_report(y_test_price, y_test_pred, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "cm = confusion_matrix(y_test_price, y_test_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=target_names, yticklabels=target_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix - Price Class Model')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature Importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': feature_columns,\n",
        "    'importance': best_rf_price.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.barh(feature_importance['feature'], feature_importance['importance'], color='steelblue')\n",
        "plt.xlabel('Importance')\n",
        "plt.title('Feature Importance - Price Class Model')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nTop 5 Important Features:\")\n",
        "print(feature_importance.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model Training - Usage Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data for Usage Type model\n",
        "X_train_usage, X_test_usage, y_train_usage, y_test_usage = train_test_split(\n",
        "    X, y_usage, test_size=0.2, random_state=42, stratify=y_usage\n",
        ")\n",
        "\n",
        "# Scale features\n",
        "X_train_usage_scaled = scaler.transform(X_train_usage)\n",
        "X_test_usage_scaled = scaler.transform(X_test_usage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Usage Type model with best params (similar approach)\n",
        "print(\"Training Usage Type model...\")\n",
        "\n",
        "rf_usage = RandomForestClassifier(\n",
        "    n_estimators=150,\n",
        "    max_depth=10,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    max_features='sqrt',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "rf_usage.fit(X_train_usage_scaled, y_train_usage)\n",
        "\n",
        "# Evaluate\n",
        "y_train_usage_pred = rf_usage.predict(X_train_usage_scaled)\n",
        "y_test_usage_pred = rf_usage.predict(X_test_usage_scaled)\n",
        "\n",
        "train_acc_usage = accuracy_score(y_train_usage, y_train_usage_pred)\n",
        "test_acc_usage = accuracy_score(y_test_usage, y_test_usage_pred)\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"USAGE TYPE MODEL EVALUATION\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Training Accuracy: {train_acc_usage:.4f}\")\n",
        "print(f\"Test Accuracy: {test_acc_usage:.4f}\")\n",
        "print(f\"Difference: {train_acc_usage - test_acc_usage:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Classification Report for Usage Type\n",
        "print(\"\\nClassification Report (Usage Type):\")\n",
        "print(\"=\"*50)\n",
        "print(classification_report(y_test_usage, y_test_usage_pred, \n",
        "                           target_names=usage_encoder.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion Matrix - Usage Type\n",
        "plt.figure(figsize=(10, 8))\n",
        "cm_usage = confusion_matrix(y_test_usage, y_test_usage_pred)\n",
        "sns.heatmap(cm_usage, annot=True, fmt='d', cmap='Greens',\n",
        "            xticklabels=usage_encoder.classes_, yticklabels=usage_encoder.classes_)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix - Usage Type Model')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Save Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Create model directory if not exists\n",
        "model_dir = '../model'\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "# Save Price Class model\n",
        "joblib.dump(best_rf_price, f'{model_dir}/smartphone_price_model.pkl')\n",
        "print(\"âœ… Price Class model saved!\")\n",
        "\n",
        "# Save Usage Type model\n",
        "joblib.dump(rf_usage, f'{model_dir}/smartphone_usage_model.pkl')\n",
        "print(\"âœ… Usage Type model saved!\")\n",
        "\n",
        "# Save Scaler\n",
        "joblib.dump(scaler, f'{model_dir}/scaler.pkl')\n",
        "print(\"âœ… Scaler saved!\")\n",
        "\n",
        "# Save feature list\n",
        "joblib.dump(feature_columns, f'{model_dir}/features.pkl')\n",
        "print(\"âœ… Feature list saved!\")\n",
        "\n",
        "# Save usage encoder\n",
        "joblib.dump(usage_encoder, f'{model_dir}/usage_encoder.pkl')\n",
        "print(\"âœ… Usage encoder saved!\")\n",
        "\n",
        "# Save price class names\n",
        "joblib.dump(price_class_names, f'{model_dir}/price_class_names.pkl')\n",
        "print(\"âœ… Price class names saved!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Test Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test prediction function\n",
        "def predict_smartphone(specs):\n",
        "    \"\"\"\n",
        "    Predict price class and usage type for a smartphone\n",
        "    \n",
        "    specs: dict with feature values\n",
        "    \"\"\"\n",
        "    # Create DataFrame\n",
        "    input_df = pd.DataFrame([specs], columns=feature_columns)\n",
        "    \n",
        "    # Scale\n",
        "    input_scaled = scaler.transform(input_df)\n",
        "    \n",
        "    # Predict\n",
        "    price_pred = best_rf_price.predict(input_scaled)[0]\n",
        "    price_proba = best_rf_price.predict_proba(input_scaled)[0]\n",
        "    \n",
        "    usage_pred = rf_usage.predict(input_scaled)[0]\n",
        "    usage_proba = rf_usage.predict_proba(input_scaled)[0]\n",
        "    \n",
        "    return {\n",
        "        'price_class': price_class_names[price_pred],\n",
        "        'price_confidence': price_proba[price_pred] * 100,\n",
        "        'usage_type': usage_encoder.classes_[usage_pred],\n",
        "        'usage_confidence': usage_proba[usage_pred] * 100\n",
        "    }\n",
        "\n",
        "# Test with sample data\n",
        "test_specs = {\n",
        "    'num_cores': 8,\n",
        "    'processor_speed': 3.2,\n",
        "    'ram_capacity': 12,\n",
        "    'internal_memory': 256,\n",
        "    'battery_capacity': 5000,\n",
        "    'screen_size': 6.7,\n",
        "    'refresh_rate': 120,\n",
        "    'primary_camera_rear': 108,\n",
        "    'primary_camera_front': 32,\n",
        "    'resolution_width': 1440,\n",
        "    'resolution_height': 3200,\n",
        "    'has_5g': 1,\n",
        "    'has_nfc': 1,\n",
        "    'fast_charging_available': 1,\n",
        "    'num_rear_cameras': 3\n",
        "}\n",
        "\n",
        "result = predict_smartphone(test_specs)\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"TEST PREDICTION\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Price Class: {result['price_class']} ({result['price_confidence']:.1f}% confidence)\")\n",
        "print(f\"Usage Type: {result['usage_type']} ({result['usage_confidence']:.1f}% confidence)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test with entry level phone\n",
        "entry_specs = {\n",
        "    'num_cores': 4,\n",
        "    'processor_speed': 1.8,\n",
        "    'ram_capacity': 3,\n",
        "    'internal_memory': 32,\n",
        "    'battery_capacity': 5000,\n",
        "    'screen_size': 6.5,\n",
        "    'refresh_rate': 60,\n",
        "    'primary_camera_rear': 13,\n",
        "    'primary_camera_front': 5,\n",
        "    'resolution_width': 720,\n",
        "    'resolution_height': 1600,\n",
        "    'has_5g': 0,\n",
        "    'has_nfc': 0,\n",
        "    'fast_charging_available': 0,\n",
        "    'num_rear_cameras': 2\n",
        "}\n",
        "\n",
        "result_entry = predict_smartphone(entry_specs)\n",
        "print(\"\\nEntry Level Phone Prediction:\")\n",
        "print(f\"Price Class: {result_entry['price_class']} ({result_entry['price_confidence']:.1f}%)\")\n",
        "print(f\"Usage Type: {result_entry['usage_type']} ({result_entry['usage_confidence']:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MODEL TRAINING SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nDataset: {len(df_clean)} smartphones\")\n",
        "print(f\"Features: {len(feature_columns)} features\")\n",
        "print(f\"\\n--- Price Class Model ---\")\n",
        "print(f\"Algorithm: Random Forest Classifier\")\n",
        "print(f\"Best Parameters: {grid_search_price.best_params_}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.2%}\")\n",
        "print(f\"CV Score: {cv_scores.mean():.2%}\")\n",
        "print(f\"\\n--- Usage Type Model ---\")\n",
        "print(f\"Test Accuracy: {test_acc_usage:.2%}\")\n",
        "print(f\"\\n--- Saved Files ---\")\n",
        "print(\"- model/smartphone_price_model.pkl\")\n",
        "print(\"- model/smartphone_usage_model.pkl\")\n",
        "print(\"- model/scaler.pkl\")\n",
        "print(\"- model/features.pkl\")\n",
        "print(\"- model/usage_encoder.pkl\")\n",
        "print(\"- model/price_class_names.pkl\")\n",
        "print(\"\\nâœ… Training completed successfully!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
